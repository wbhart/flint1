

=== general stuff ===

 * try GREDC algorithm

 * add some kind of debug flag to the makefile, which will enable/disable
   FLINT_ASSERT
   
 * we should be checking somewhere (at build time?) that FLINT_BITS_PER_LIMB
   really is the same as GMP's bits per limb

 * cache hints:
    * add some documentation for cache hint macros in flint.h
    * instead of having loops like 
             for (j = 0; j < x->n; j += 8) FLINT_PREFETCH(x->coeffs[i+8], j);
      everywhere, can't we have a FLINT_BLOCK_PREFETCH macro?
 
 * determine cache size at build time, instead of #defined in flint.h!!!!
     * possibly determine size of each cache in hierarchy?
 
 * generally clean up the makefile -- it's really grossly disgusting right now

 * Write some decent profiling code.

 * Make sure to use mpz_rrandomb for all randomised testing, it's much better
   at picking up corner cases. Make sure it isn't used in the profiling code, 
   since GMP uses a faster algorithm for multiplying such numbers.

 * Think more about the odd-even karatsuba idea -- david suspects it might
   give smoother performance for unequal length inputs

 * Profile our code to date in the Z and polynomials over Z packages.

 * Write a test module for Z and polynomials over Z packages. Move all
 existing test code into that module.

 * Collect together timing statistics on various programs (MAGMA, NTL, PARI,
FLINT, etc), in one convenient place. (David)

 * Write an asymptotically fast GCD algorithm for the Z package for very
large integers. (First check how far along the GMP implementation is, and
compare it speedwise to MAGMA (which presumably is very fast :-) )

 * line endings. All of bill's files have DOS/Windows line endings :-) Some of
the other files don't. Is this a problem?

 * follow up issue related to arithmetic right shifts --- see NTL's #define for this. Add test code to the build process to check for this.

 * write threadsafe limb allocator (does this even make sense at all with a
   stack-based model?)


=== Build process ===

 * on the G5 architecture, the flags 
      -mcpu=970 -mtune=970 -mpowerpc64 -falign-loops=16 -falign-functions=16 -falign-labels=16 -falign-jumps=16
   seem to make a helluva difference, at least for the ssfft_fft_iterative()
   function I was profiling.

 * Figure out `FLINT_BITS_PER_LIMB`, put it in a header somewhere (do ''not''
just use `gmp_bits_per_limb` because that's a const, not a #define)

 * Figure out FLINT_CACHE_SIZE


=== ssfft module ===

* GMP has a cool idea for doing very long butterflies. Instead of doing
a call to mpn_add_n and mpn_sub_n separately, it works in chunks to ensure
everything is done in cache. This will only make a difference when the
coefficients are so large they don't even fit in L1 any more. To do this
*properly* it would need to work for rotations as well.

* Is there a way to do reduce_mod_p_exact with one pass over the data in the
worst case? (Currently the worst case is two passes.)

* study the the overflow bit guarantees more carefully in the
  inverse transform. The cross butterflies seem to add a factor of 3 rather
  than 2 to the errors. Currently we are being too conservative in doing
  fast reductions; we could get away with fewer, but would need to do a
  safety reduction pass over the data after a certain number of layers.


=== ssmul module ===

* maybe it's not optimal to store the coefficients n+1 limbs apart. Bill
mentioned some potential cache-thrashing issues on intels. Might be better
to add a bit of padding.

* the 0th and (n/2)th fourier coefficients are always about half the size of
  the others. (These are the two stored first in the bit-reversed array.)
  Take advantage of this when doing pointwise mults there.

* negacylic convolutions for pointwise mults when the coefficients are
  large enough. Also chase up that reference in the paper by Zimmerman et al
  for some kind of wrapped-around toom cook.

* for KS, try the idea where we evaluate X1 = f(2^n)g(2^n), X2 = f(-2^n)g(-2^n) and then reconstruct output from X1+X2 and X1-X2



=== Zpoly_mpn module ===

* Ensure the documentation agrees with the implementation of the sign limb.

* I'm not comfortable with the way _Zpoly_mpn_mul_KS modifies its input
  temporarily if the signs are wrong. What happens if a multithreaded
  application wants to do two things with the poly at the same time.
  Surely it's possible to accomplish the same thing without mutating
  the input. -- david

* It seems a little nuts to be using ZmodFpoly with a single coefficient
  in _Zpoly_mpn_mul_KS(). There's something wrong with the code structure here.
  The bitpacking etc routines need to be abstracted differently or something.
  -- david

* we should change the name of ABS() in Zpoly_mpn. This will certainly interfere
  with someone else's namespace one day. -- david

* I think the the bitpacking/limbpacking/bytepacking routines should be
  moved out of ZmodFpoly.c into Zpoly_mpn.c.


=== modpmul module ===

* try writing assembly version of mul_redc. Maybe the three multiplications
can be pipelined. Also, it might be possible to write a version which does
two independent multiplications in parallel, and gets some pipelining
happening that way. But that would require rewriting FFTs to take advantage
of it.

* consider writing a radix-4 or split-radix FFT. I don't understand these too
well, but it seems like these only give a speedup on "complex" data. There
was a paper Bill mentioned that simulates a "complex" FFT by working over
GF(p^2), so perhaps this could be used.

* see whether doing two FFT's at once saves time on computing roots of unity
and whether the multiplications being data independent might allow them to be
interleaved and thus overlapped due to pipelining on the Opteron.

* try to speed up basecase matrix transposition code

* examine NTL's modmuls more carefully. Benchmark just the modmuls by
themselves.

* think about the ordering of loops in each stage of the outer fft routine.
Sometimes might be slightly better to start at the end and work backwards
to improve locality.


=== ZmodF module ===

* in revision 507, I rewrote ZmodF_mul_2exp(). For long coefficients the new
  version should be more efficient, since it does fewer passes over the data
  on average. But this needs to be checked. Moreover it's quite possible the
  new version is slower for small coefficients, which also needs to be
  investigated.


=== ZmodFpoly module ===

* reorganise code to permit doing pointwise mults + inner FFTs + inner IFFTs with better locality

=== profiler-main module ===

* this module should supply a random number generating object so that profiling code doesn't have to worry about it


=== memory manager ===

* the current implementation is not O(1), since it might need to traverse
the stack. This could be a problem if we need to allocate many small objects.


=== ZmodF_mul module ===

* remember when doing the automatic tuning for this, squaring and multiplication probably have different crossovers

=== Miscellaneous ===

* Switch to integer increments instead of rounded floating point ones in  Zpoly_mpn-profile.c and magma-profile.m

* Add memory manager to Zpoly.c

* Use stack based memory manager in ZmodFpoly-test.c

* Remove randstate memory leak from Z_mul_timing.c

* Make long-extras module and redistribute extras file

* Write new faster bitpacking routines (include support for 32 bit machines)

* Compute number of limbs needed for test_mpn_poly3 in Zpoly_mpn_test.c

* Think about ways of lowering the system time in delta_qexp

* Implement karatsuba for sparse polynomials

* Write tests for double underscore functions in Zpoly_mpn.c

* Check all Zpoly_mpn functions deal appropriately with the zero length poly

* Make karatsuba use the right number of limbs
